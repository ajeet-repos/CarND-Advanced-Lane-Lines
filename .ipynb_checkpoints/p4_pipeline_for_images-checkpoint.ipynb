{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pickle\n",
    "from matplotlib.path import Path\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Methods\n",
    "\n",
    "This section include methods for sobel and all other action required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# appliying direction gradient on the image in x-axis\n",
    "def performSobelX(image, sobel_kernal=3):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    return cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernal)\n",
    "    \n",
    "# appliying direction gradient on the image in y-axis\n",
    "def performSobelY(image, sobel_kernal=3):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    return cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# applying the threshold on directional gradient\n",
    "def performSobelGradientThreshold(image, axis='x', sobel_kernal=3, sobel_thresh=(10,100)):\n",
    "    \n",
    "    if axis is 'x':\n",
    "        abs_sobel = np.absolute(performSobelX(image, sobel_kernal))\n",
    "    else:\n",
    "        abs_sobel = np.absolute(performSobelY(image, sobel_kernal))\n",
    "    \n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    \n",
    "    s_binary = np.zeros_like(scaled_sobel)\n",
    "    s_binary[(scaled_sobel >= sobel_thresh[0]) & (scaled_sobel < sobel_thresh[1])] = 1\n",
    "    \n",
    "    return s_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# applying the threshold on the magnitude of the gradient\n",
    "def performGradientMagnitudeThreshold(image, axis='x', sobel_kernal=3, mag_thresh=(0,255)):\n",
    "\n",
    "    gradmag = None\n",
    "    if axis is 'x':\n",
    "        sobelx = performSobelX(image, sobel_kernal)\n",
    "        gradmag = np.sqrt(sobelx**2)\n",
    "    elif axis is 'y':\n",
    "        sobely = performSobelY(image, sobel_kernal)\n",
    "        gradmag = np.sqrt(sobely**2)\n",
    "    elif axis is 'xy':\n",
    "        sobelx = performSobelX(image)\n",
    "        sobely = performSobelY(image)\n",
    "        gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    else:\n",
    "        return null\n",
    "    \n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "    return binary_output\n",
    "    \n",
    "# applying threshold on the direction of the gradient\n",
    "def performGradientDirectionThreshold(image, sobel_kernal=3, dir_thresh=(0, np.pi/2)):\n",
    "    sobelx = performSobelX(image, sobel_kernal)\n",
    "    sobely = performSobelY(image, sobel_kernal)\n",
    "    \n",
    "    absgraddir = np.arctan(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_img = np.zeros_like(absgraddir)\n",
    "    binary_img[(absgraddir >= dir_thresh[0]) & (absgraddir < dir_thresh[1])] = 1\n",
    "    \n",
    "    return binary_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ploting two image side by side\n",
    "def plot_images(img1, img2, title1, title2):\n",
    "    plt.clf()\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img1, cmap='gray')\n",
    "    ax1.set_title(title1, fontsize=50)\n",
    "    ax2.imshow(img2, cmap='gray')\n",
    "    ax2.set_title(title2, fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# method to return the#age, thresh=(0,255)):\n",
    "def performHLSThreshold(image, thresh=(0, 255)):\n",
    "    hls_img = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    s = hls_img[:,:,2]\n",
    "    output = np.zeros_like(s)\n",
    "    output[(s > thresh[0]) & (s <= thresh[1])] = 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cal_undistort(orig_img, objpoints, imgpoints):\n",
    "    gray_img = cv2.cvtColor(orig_img, cv2.COLOR_RGB2GRAY)\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray_img.shape[::-1], None, None)\n",
    "    undist = cv2.undistort(orig_img, mtx, dist, None, mtx)\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# img_binary is supposed to be the final output after applying all the thresholding\n",
    "# like color, gradient, etc on the image\n",
    "def performPerspectiveTransform(img_binary, src_points, dst_points):\n",
    "    img_size = (img_binary.shape[1], img_binary.shape[0])\n",
    "    # take the src and dst points and calculate the perspective transform\n",
    "    M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "    warped = cv2.warpPerspective(img_binary, M, img_size)\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# implementing sliding window algo and fitting a polynomial\n",
    "def laneDetectionUsingSlidingWindowsSearch(binary_warped):\n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    plt.imshow(out_img)\n",
    "    plt.plot(left_fitx, ploty, color='red')\n",
    "    plt.plot(right_fitx, ploty, color='red')\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)\n",
    "    plt.imshow(warped, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    return ploty, left_fit, right_fit, left_fitx, right_fitx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findLaneCurvatur(ploty, left_fit, right_fit):\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "    y_eval = np.max(ploty)\n",
    "    left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "    print(left_curverad, right_curverad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this method will take the lane image and return the image with lane area, curvature and offset from center marked\n",
    "def findAndPlotLaneLines(image, obj_points, img_points, sobel_kernal=3,\n",
    "                         s_thresh=(0,255), mag_thresh=(40,160),\n",
    "                        dir_thresh=(0.5,1.5), sobel_thresh=(0,100)):\n",
    "    # 1. undistort the images\n",
    "    undistored = cal_undistort(image, objpoints=obj_points, imgpoints=img_points)\n",
    "    # 2. color thresholding with s-channel\n",
    "    s_channel_binary = performHLSThreshold(undistored, thresh=s_thresh)\n",
    "    # 3. perform various thresholding on the image\n",
    "    # 3.a. gradient thresholding in single direction. As lanes are more closer to vertical, hence taking soble on x-axis\n",
    "    sobel_grad = performSobelGradientThreshold(undistored, axis='x', sobel_kernal=sobel_kernal, sobel_thresh=sobel_thresh)\n",
    "    # 3.b gradient magnitude thresholding\n",
    "    mag_binary = performGradientMagnitudeThreshold(undistored, axis='x', sobel_kernal=sobel_kernal, mag_thresh=mag_thresh)\n",
    "    # 3.c. gradient direction thresholding\n",
    "    dir_binary = performGradientDirectionThreshold(undistored, sobel_kernal=sobel_kernal, dir_thresh=dir_thresh)\n",
    "    # 4. create a combined binary of all above thresholding -\n",
    "    # s-channel image with all above gradient related thresholding.\n",
    "    all_combined_binary = np.zeros_like(dir_binary)\n",
    "    all_combined_binary[(s_channel_binary == 1) | (sobel_grad == 1) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    # 5. perform perspective transform\n",
    "    # 5.a declaring source points and destination points. These points are choosen at random in begining\n",
    "    # and tweaked in subsequent attempts. Basic idea was to keep source points are corners of a trapezium\n",
    "    # and destination points as corners of a rectangle\n",
    "    src = np.float32([(220,700), (590,450), (685,450), (1090,700)])\n",
    "    dst = np.float32([(200,700), (200,0), (1000,0), (1000,700)])\n",
    "    warped_binary = performPerspectiveTransform(all_combined_binary, src_points=src, dst_points=dst)\n",
    "    # 6. increase the hot points in the image\n",
    "    # 7. perform sliding windows search algorithm for finding lane lines and fitting a polygon\n",
    "    ploty, left_fit, right_fit, left_fitx, right_fitx = laneDetectionUsingSlidingWindowsSearch(warped)\n",
    "    # 8. mark the area of lane lines\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    # 9. undistort the image back to starting perspective and return\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (sl1_img.shape[1], sl1_img.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undistored, 1, newwarp, 0.3, 0)\n",
    "    plot_images(image, result, 'image 1', 'image 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing above pipeline for lane images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the image and object points from disk. This data has been saved after\n",
    "# calibrating it over given chessboard images\n",
    "# Please refer to **p4_chessboard_image_processing.ipynb** for camera calibration code\n",
    "obj_points = []\n",
    "img_points = []\n",
    "with open('obj_img_points.pickle', 'rb') as handle:\n",
    "    a = pickle.load(handle)\n",
    "    obj_points = a['objpoints']\n",
    "    img_points = a['imgpoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'performSlidingWindowSearch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-61506700d229>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m findAndPlotLaneLines(sl1_img, obj_points=obj_points, img_points=img_points,\n\u001b[1;32m      4\u001b[0m                      \u001b[0ms_thresh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmag_thresh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m160\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdir_thresh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     sobel_thresh=(50,150))\n\u001b[0m",
      "\u001b[0;32m<ipython-input-84-d1460bfecb4c>\u001b[0m in \u001b[0;36mfindAndPlotLaneLines\u001b[0;34m(image, obj_points, img_points, sobel_kernal, s_thresh, mag_thresh, dir_thresh, sobel_thresh)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[1;31m# 6. increase the hot points in the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[1;31m# 7. perform sliding windows search algorithm for finding lane lines and fitting a polygon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mploty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_fitx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_fitx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperformSlidingWindowSearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwarped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[1;31m# 8. mark the area of lane lines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[1;31m# Create an image to draw the lines on\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'performSlidingWindowSearch' is not defined"
     ]
    }
   ],
   "source": [
    "sl1_img = mpimg.imread('test_images\\\\straight_lines1.jpg')\n",
    "sobel_kernal = 15\n",
    "findAndPlotLaneLines(sl1_img, obj_points=obj_points, img_points=img_points,\n",
    "                     s_thresh=(60,255), mag_thresh=(40,160), dir_thresh=(0,1.5),\n",
    "                    sobel_thresh=(50,150))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
